{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "8WmCVEJzlGmX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HUAnXSle8JTs",
    "outputId": "02eebb20-8b7e-458e-a613-4f001053d384"
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7KcNCGJB8J29"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrhfVO75qqwL",
    "outputId": "06d811a6-614a-48f9-9c62-d91368290651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in g:\\anaconda\\lib\\site-packages (2.2.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Requirement already satisfied: tqdm in g:\\anaconda\\lib\\site-packages (from sentence_transformers) (4.63.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in g:\\anaconda\\lib\\site-packages (from sentence_transformers) (1.11.0)\n",
      "Requirement already satisfied: scikit-learn in g:\\anaconda\\lib\\site-packages (from sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: huggingface-hub in g:\\anaconda\\lib\\site-packages (from sentence_transformers) (0.5.1)\n",
      "Requirement already satisfied: nltk in g:\\anaconda\\lib\\site-packages (from sentence_transformers) (3.7)\n",
      "Requirement already satisfied: torchvision in g:\\anaconda\\lib\\site-packages (from sentence_transformers) (0.12.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\zuqing\\appdata\\roaming\\python\\python38\\site-packages (from sentence_transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy in g:\\anaconda\\lib\\site-packages (from sentence_transformers) (1.19.2)\n",
      "Requirement already satisfied: sentencepiece in g:\\anaconda\\lib\\site-packages (from sentence_transformers) (0.1.96)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in g:\\anaconda\\lib\\site-packages (from sentence_transformers) (4.18.0)\n",
      "Requirement already satisfied: typing-extensions in g:\\anaconda\\lib\\site-packages (from torch>=1.6.0->sentence_transformers) (4.1.1)\n",
      "Requirement already satisfied: sacremoses in g:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.0.49)\n",
      "Requirement already satisfied: filelock in g:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (3.6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in g:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: requests in g:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2.27.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in g:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in g:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in g:\\anaconda\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in g:\\anaconda\\lib\\site-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.0.4)\n",
      "Requirement already satisfied: colorama in g:\\anaconda\\lib\\site-packages (from tqdm->sentence_transformers) (0.4.4)\n",
      "Requirement already satisfied: click in g:\\anaconda\\lib\\site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in g:\\anaconda\\lib\\site-packages (from nltk->sentence_transformers) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in g:\\anaconda\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in g:\\anaconda\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in g:\\anaconda\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in g:\\anaconda\\lib\\site-packages (from requests->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.26.9)\n",
      "Requirement already satisfied: six in g:\\anaconda\\lib\\site-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence_transformers) (1.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in g:\\anaconda\\lib\\site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in g:\\anaconda\\lib\\site-packages (from torchvision->sentence_transformers) (9.0.1)\n",
      "Requirement already satisfied: emoji in g:\\anaconda\\lib\\site-packages (0.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow (g:\\anaconda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (g:\\anaconda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers\n",
    "!pip install emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O3hhqZEQoGX0",
    "outputId": "dd693c0b-3f5f-44c0-e9d6-036c673c6b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "tuDbgShzog2H"
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_dev = []\n",
    "train_ids = open(\"drive/MyDrive/NLP_dataset/train.data.txt\", 'r').readlines()\n",
    "dev_ids = open(\"drive/MyDrive/NLP_dataset/dev.data.txt\", 'r').readlines()\n",
    "test_ids = open(\"drive/MyDrive/NLP_dataset/test.data.txt\", 'r').readlines()\n",
    "data = json.load(open(\"drive/MyDrive/NLP_dataset/data.txt\"))\n",
    "data_dev = json.load(open(\"drive/MyDrive/NLP_dataset/data_dev.txt\"))\n",
    "y_train_t = open('drive/MyDrive/NLP_dataset/train.label.txt','r').readlines()\n",
    "y_dev_t = open('drive/MyDrive/NLP_dataset/dev.label.txt','r').readlines()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train_t = open('train.label.txt','r').readlines()\n",
    "y_dev_t = open('dev.label.txt','r').readlines()\n",
    "train_ids = open(\"train.data.txt\", 'r').readlines()\n",
    "dev_ids = open(\"dev.data.txt\", 'r').readlines()\n",
    "test_ids = open(\"test.data.txt\", 'r').readlines()\n",
    "data = json.load(open(\"data.txt\"))\n",
    "data_dev = json.load(open(\"data_dev.txt\"))\n",
    "X_train = []\n",
    "X_dev = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "S3LkqmNdojXP"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "tra_data = []\n",
    "tra_data2 = []\n",
    "\n",
    "y_train = []\n",
    "train_additional = []\n",
    "for i in range(len(train_ids)):\n",
    "    ids = train_ids[i]\n",
    "    ids = ids.strip().split(\",\")\n",
    "    temp = []\n",
    "    \n",
    "    for j in range(len(ids)):\n",
    "        ele = ids[j]\n",
    "        for ele2 in data[i]:\n",
    "            if ele == str(ele2['id']):\n",
    "                temp.append(ele2)\n",
    "        if j == 0 and temp == []:\n",
    "            break\n",
    "    if temp == []:\n",
    "        continue        \n",
    "    temp2 = sorted(list(temp[1:]) , key = lambda x : time.mktime(time.strptime(x['created_at'], \"%a %b %d %H:%M:%S %z %Y\")))\n",
    "    temp3 = [temp[0]] + temp2\n",
    "    temp3 = list(map(lambda x : x['text'],temp3)) \n",
    "    tra_data += temp3\n",
    "    tra_data2.append(temp3)\n",
    "    label = y_train_t[i]\n",
    "    train_additional.append(\n",
    "        [int(temp[0]['user']['followers_count']),\n",
    "         int(temp[0]['user']['friends_count']),\n",
    "         int(temp[0]['user']['statuses_count']),\n",
    "         int(temp[0]['user']['favourites_count']),\n",
    "         int(temp[0]['user']['verified']),\n",
    "         float(time.mktime(time.strptime(temp[0]['created_at'], \"%a %b %d %H:%M:%S %z %Y\"))\n",
    "         -time.mktime(time.strptime(temp[0]['user']['created_at'], \"%a %b %d %H:%M:%S %z %Y\")))/31536000\n",
    "         ])\n",
    "    if label == 'nonrumour\\n':\n",
    "        y_train.append(0)\n",
    "    else:\n",
    "        y_train.append(1)\n",
    "\n",
    "dev_data = []\n",
    "dev_data2 = []\n",
    "y_dev = []\n",
    "dev_additional = []\n",
    "for i in range(len(dev_ids)):\n",
    "    ids = dev_ids[i]\n",
    "    ids = ids.strip().split(\",\")\n",
    "    temp = []\n",
    "    for j in range(len(ids)):\n",
    "        ele = ids[j]\n",
    "        for ele2 in data_dev[i]:\n",
    "            if ele == str(ele2['id']):\n",
    "                temp.append(ele2)\n",
    "        if j == 0 and temp == []:\n",
    "            break\n",
    "    if temp == []:\n",
    "        continue\n",
    "    temp2 = sorted(temp[1:] , key = lambda x : time.mktime(time.strptime(x['created_at'], \"%a %b %d %H:%M:%S %z %Y\")))\n",
    "    temp3 = [temp[0]] + temp2\n",
    "    temp3 = list(map(lambda x : x['text'],temp3)) \n",
    "    dev_data += temp3\n",
    "    dev_data2.append(temp3)\n",
    "\n",
    "    dev_additional.append(\n",
    "        [int(temp[0]['user']['followers_count']),\n",
    "         int(temp[0]['user']['friends_count']),\n",
    "         int(temp[0]['user']['statuses_count']),\n",
    "         int(temp[0]['user']['favourites_count']),\n",
    "         int(temp[0]['user']['verified']),\n",
    "         float(time.mktime(time.strptime(temp[0]['created_at'], \"%a %b %d %H:%M:%S %z %Y\"))\n",
    "         -time.mktime(time.strptime(temp[0]['user']['created_at'], \"%a %b %d %H:%M:%S %z %Y\")))/31536000\n",
    "         ])\n",
    "    \n",
    "    label = y_dev_t[i]\n",
    "    if label == 'nonrumour\\n':\n",
    "        y_dev.append(0)\n",
    "    else:\n",
    "        y_dev.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0TX7aq2iopg7",
    "outputId": "2beb3bd7-c89a-4fd6-f460-3d51d1994b63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4. can eating garlic help prevent infection with the new coronavirus? #covid19malaysia\n",
      "covid-19 fact: are hand dryers effective in killing the new coronavirus?  share the information with your loved one…\n"
     ]
    }
   ],
   "source": [
    "tt = TweetTokenizer()\n",
    "#stopwords = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(lst):\n",
    "    temp = []\n",
    "    #list of tweets\n",
    "    for tweet in lst:\n",
    "        tweet = tweet.strip().split(\" \")\n",
    "        \n",
    "\n",
    "        tweet = list(map(lambda x: x.lower(), tweet))\n",
    "        #tweet = list(map(lambda x: x.isalpha(), tweet))\n",
    "        #remove any word that does not contain any English alphabets\n",
    "        #tweet = list(map(lambda x: re.sub(\"^[^a-z\\d]+$\", \"\", x).strip(), tweet))\n",
    "        tweet = list(map(lambda x: re.sub(\"^(http).*$\", \"\", x).strip(), tweet))\n",
    "        #tweet = list(map(lambda x: re.sub(\"[^\\w\\s@#]\", \"\", x).strip(), tweet))\n",
    "        tweet = list(map(lambda x: re.sub(\"^[@].*$\", \"\", x).strip(), tweet))\n",
    "        tweet = list(map(lambda x: re.sub(\"\\n\", \" \", x).strip(), tweet))\n",
    "        #remove all '' in the list\n",
    "        tweet = list(filter(lambda x: x != 'rt', tweet))\n",
    "        tweet = list(filter(lambda x: x != '', tweet))\n",
    "        #tweet = list(filter(lambda x: x not in stopwords, tweet))\n",
    "        tweet = ' '.join(tweet)\n",
    "        temp.append(tweet)\n",
    "    return temp\n",
    "\n",
    "\n",
    "text_data = preprocess(tra_data)\n",
    "print(text_data[1])\n",
    "text_dev_data = preprocess(dev_data)\n",
    "print(text_dev_data[0])\n",
    "\n",
    "# test_id = open(\"drive/MyDrive/NLP_dataset/test.data.txt\", 'r').readlines()\n",
    "# test_data = []\n",
    "# test_additional = []\n",
    "# for i in range(len(test_id)):\n",
    "#     ids = test_id[i]\n",
    "#     ids = ids.strip().split(\",\")\n",
    "#     temp = []\n",
    "#     for ele in ids:\n",
    "#         temp.append(json.load(open(\"drive/MyDrive/NLP_dataset/test-tweet-objects/\" + str(ele) + \".json\")))\n",
    "#     temp2 = sorted(temp[1:] , key = lambda x : time.mktime(time.strptime(x['created_at'], \"%a %b %d %H:%M:%S %z %Y\")))\n",
    "#     temp3 = [temp[0]] + temp2\n",
    "    \n",
    "#     test_additional.append(\n",
    "#         [int(temp[0]['user']['followers_count']),\n",
    "#          int(temp[0]['user']['friends_count']),\n",
    "#          int(temp[0]['user']['statuses_count']),\n",
    "#          int(temp[0]['user']['favourites_count']),\n",
    "#          int(temp[0]['user']['verified']),\n",
    "#          float(time.mktime(time.strptime(temp[0]['created_at'], \"%a %b %d %H:%M:%S %z %Y\"))-time.mktime(time.strptime(temp[0]['user']['created_at'], \"%a %b %d %H:%M:%S %z %Y\")))/31536000\n",
    "#          ])\n",
    "#     # temp4 = list(map(lambda x : x['text'],temp3)) \n",
    "#     test_data.append(temp3)\n",
    "    \n",
    "# text_test_data = []\n",
    "# for ele in test_data:\n",
    "#     temp = list(map(lambda x : x['text'],ele))\n",
    "#     temp = preprocess(temp)\n",
    "#     text_test_data += temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ybZ0dN6Ou7Pb",
    "outputId": "6019a4c5-0665-4a62-8065-4b53afe09993"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: re.sub(\"RT\", \"\", x).strip(), ['RT RT RTT']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = open(\"test.data.txt\", 'r').readlines()\n",
    "test_data = []\n",
    "for i in range(len(test_id)):\n",
    "    ids = test_id[i]\n",
    "    ids = ids.strip().split(\",\")\n",
    "    temp = []\n",
    "    for ele in ids:\n",
    "        temp.append(json.load(open(\"tweet-objects/tweet-objects/\" + str(ele) + \".json\")))\n",
    "    temp2 = sorted(temp[1:] , key = lambda x : time.mktime(time.strptime(x['created_at'], \"%a %b %d %H:%M:%S %z %Y\")))\n",
    "    temp3 = [temp[0]] + temp2\n",
    "    #temp3 = list(map(lambda x : x['text'],temp3)) \n",
    "    test_data.append(temp3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "id": "XoJicnxthnk4"
   },
   "outputs": [],
   "source": [
    "test_data = json.load(open(\"drive/MyDrive/NLP_dataset/data_test.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-pW_-nF3hy7g"
   },
   "outputs": [],
   "source": [
    "test_additional = []\n",
    "text_test_data = []\n",
    "y_test = []\n",
    "for temp in test_data:\n",
    "    test_additional.append(\n",
    "        [int(temp[0]['user']['followers_count']),\n",
    "         int(temp[0]['user']['friends_count']),\n",
    "         int(temp[0]['user']['statuses_count']),\n",
    "         int(temp[0]['user']['favourites_count']),\n",
    "         int(temp[0]['user']['verified']),\n",
    "         float(time.mktime(time.strptime(temp[0]['created_at'], \"%a %b %d %H:%M:%S %z %Y\"))-time.mktime(time.strptime(temp[0]['user']['created_at'], \"%a %b %d %H:%M:%S %z %Y\")))/31536000\n",
    "         ])\n",
    "    temp1 = list(map(lambda x : x['text'],temp))\n",
    "    temp1 = preprocess(temp1)\n",
    "    text_test_data += temp1\n",
    "\n",
    "# for i in range(len(test_ids)):\n",
    "#     ids = test_ids[i]\n",
    "#     ids = ids.strip().split(\",\")\n",
    "#     temp = []\n",
    "#     for j in range(len(ids)):\n",
    "#         ele = ids[j]\n",
    "#         for ele2 in test_data[i]:\n",
    "#             if ele == str(ele2['id']):\n",
    "#                 temp.append(ele2)\n",
    "#         if j == 0 and temp == []:\n",
    "#             break\n",
    "#     if temp == []:\n",
    "#         continue\n",
    "    \n",
    "#     label = y_test_t[i]\n",
    "#     if label == 'nonrumour\\n':\n",
    "#         y_test.append(0)\n",
    "#     else:\n",
    "#         y_test.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "YCz5jJb8qIt5"
   },
   "outputs": [],
   "source": [
    "y_train = np.array(y_train)\n",
    "y_dev = np.array(y_dev)\n",
    "\n",
    "train_additional = np.array(train_additional)\n",
    "dev_additional = np.array(dev_additional)\n",
    "test_additional = np.array(test_additional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gzTHg7aoq0Q7",
    "outputId": "181b2ad5-ada5-4cfa-a4be-89de1fd82a0a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7996"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SvmgdVrnihC4"
   },
   "outputs": [],
   "source": [
    "def rebuild(embeddings,file):\n",
    "    lst = []\n",
    "    idx = 0\n",
    "    for i in range(len(file)):\n",
    "        temp = []\n",
    "        ids = file[i]\n",
    "        for ele in ids:\n",
    "            temp.append(embeddings[idx])\n",
    "            idx+=1\n",
    "        lst.append(temp)\n",
    "    return lst\n",
    "train_data_rebuilt = rebuild(text_data,tra_data2)\n",
    "dev_data_rebuilt = rebuild(text_dev_data,dev_data2)\n",
    "test_data_rebuilt = rebuild(text_test_data,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FvSjiD4ljaYD",
    "outputId": "ac090af2-acce-4511-fdcc-1f6babd5bdbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5. can regularly rinsing your nose with saline help prevent infection with the new coronavirus?',\n",
       " '4. can eating garlic help prevent infection with the new coronavirus? #covid19malaysia',\n",
       " '6. do vaccines against pneumonia protect you against the new coronavirus?',\n",
       " '7. can spraying alcohol or chlorine all over your body kill the new coronavirus? #chamber',\n",
       " '8. how effective are thermal scanners in detecting people infected with the new coronavirus?',\n",
       " '9. can an ultraviolet disinfection lamp kill the new coronavirus?',\n",
       " '10. are hand dryers effective in killing the new coronavirus?',\n",
       " '11. the new coronavirus cannot be transmitted through mosquito bites.',\n",
       " '12. taking a hot bath does not prevent the new coronavirus disease',\n",
       " '13. cold weather and snow cannot kill the new coronavirus.',\n",
       " '14. covid-19 virus can be transmitted in areas with hot and humid climates',\n",
       " '15. drinking alcohol does not protect you against covid-19 and can be dangerous',\n",
       " '16. being able to hold your breath for 10 seconds or more without coughing or feeling discomfort does not mean you…',\n",
       " '17. you can recover from the coronavirus disease (covid-19). catching the new coronavirus does not mean you will ha…',\n",
       " '18. exposing yourself to the sun or to temperatures higher than 25c degrees does not prevent the coronavirus diseas…',\n",
       " '19. 5g mobile networks do not spread covid-19']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_rebuilt[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "m45nNo_ejpPJ"
   },
   "outputs": [],
   "source": [
    "train_data_concatenated = [' '.join(sentence) for sentence in train_data_rebuilt]\n",
    "dev_data_concatenated = [' '.join(sentence) for sentence in dev_data_rebuilt]\n",
    "test_data_concatenated = [' '.join(sentence) for sentence in test_data_rebuilt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "tRhOOycaodoO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1566\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data_concatenated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "WZyKzfmDqIOh"
   },
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# bert_model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# print(\"Done loading BERT model.\")\n",
    "\n",
    "# #load BERT's WordPiece tokenisation model\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "U3ydtqOhqJFO"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m sentence \u001b[38;5;241m=\u001b[39m train_data_concatenated[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m----> 2\u001b[0m tokens \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mtokenize(sentence)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(tokens)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "sentence = train_data_concatenated[2]\n",
    "tokens = tokenizer.tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPJ_sXIEsTiG"
   },
   "outputs": [],
   "source": [
    "tokenizer.convert_tokens_to_ids(tokens)[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-Fx5Ju74rAJZ"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237,
     "referenced_widgets": [
      "5525864516fa4a9dbe3d339e4b72c66a",
      "29bfbc1c878f461fad13534524bc6bd8",
      "8a298906448646e2b01f6e10feabdb10",
      "18ea6393dc4c48b191c2bf093e076bd6",
      "7757b8faf63b447bb4393f56c1c905dd",
      "9554f30caa9f45de91ff9145fb89f223",
      "20c0f14bf56341d4997bad737072d5d7",
      "aca093bd94e043c2a2cb40808c531b25",
      "ffe912f15e7543f396be439177375e87",
      "b2aadb0f485548beb2fec780f402db0f",
      "31f3d4f05f3e4f709eb18d83247350f5",
      "5b30c831f0c9470eb1372c3d9d70a505",
      "c69e540a903942a3abed6113f8cbb614",
      "07484f1e51144e20bade63b314b25f85",
      "7f3a566e218e4f2c81e1a1bd2c7e0845",
      "8ba31786a08745d0902ed353ffca8698",
      "bb476ccfe9a042ee929f08427feee398",
      "460fd4497e444a0d837b78b48cd0902e",
      "fcfd4900c40c418aa98c722fe18e7541",
      "8fdce060e94e415f83517dbdb78dcff0",
      "500347b066ea42dfbd0eb60ffce509c8",
      "5bb0b8f8400c4d3cbe71ae18c22631d1",
      "39f18c40b88c48e68023c1702c4e0917",
      "532ceae399644f42aaafd22b77927ffb",
      "a47b58dd2dac468d8399105699b25a4a",
      "1085b6e331b44341aa3b00c3d593ff7b",
      "ba9f03fd9dec4ab79a438c56a009183f",
      "0bb6df41df624a748f20d3954482f5c7",
      "fcc76ed5a32b4075a8301cd2bd48566e",
      "fe7ae1cd82bf41bcb789a28898b7113c",
      "dd8e246c522c48dc97e504c01fa380e7",
      "a915344a9a494b46924f4b2a1d4ff636",
      "0d4a80b1185d4ece8389abe181932dfc",
      "45b2a914e9e145d591a1a8f91b1fa0a1",
      "608eb86bda3f4ede8ecef68e6e16cdcb",
      "e6c8d80a49414169b03c2542430d6ab7",
      "7e18fcb123844cbea80966d3110d6244",
      "2cb358b2d131453f86cce27695828315",
      "be7d951aa1d7449fb0690fa9054665d8",
      "db74716cb2ff404e9db46acd84f2846f",
      "eb53b1ffe64b41b6b6441a3dbee00f45",
      "eca6fd45776549c0a8c7065dd2feee6c",
      "ee82db5c4e944fc88403d720429f84e0",
      "35c6a5a621ff410bbcb1f3f9d69f2491"
     ]
    },
    "id": "fjo1yUI_v_yk",
    "outputId": "2e67e955-96f4-41ad-cfcb-eddb29da243d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51e517abe9494ff99d19cd089c63a9ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "bertweet = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8Pn1o0c5rwYK"
   },
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "\n",
    "    def __init__(self, series, labels, maxlen):\n",
    "\n",
    "        #Store the contents of the file in a pandas dataframe\n",
    "        # if labels==False:\n",
    "        #   self.df = pd.DataFrame({\"sentence\":series, \"label\":[\"NaN\" for i in series]})\n",
    "        # else:\n",
    "        self.df = pd.DataFrame({\"sentence\":series, \"label\":labels})\n",
    "        \n",
    "        #Initialize the BERT tokenizer\n",
    "        #self.tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\")\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        #Selecting the sentence and label at the specified index in the data frame\n",
    "        sentence = self.df.loc[index, 'sentence']\n",
    "        label = self.df.loc[index, 'label']\n",
    "\n",
    "        #Preprocessing the text to be suitable for BERT\n",
    "        tokens = self.tokenizer.tokenize(sentence) #Tokenize the sentence\n",
    "        tokens = [t for t in tokens if t != 'UNK']\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]'] #Insering the CLS and SEP token in the beginning and end of the sentence\n",
    "        if len(tokens) < self.maxlen:\n",
    "            tokens = tokens + ['[PAD]' for _ in range(self.maxlen - len(tokens))] #Padding sentences\n",
    "        else:\n",
    "            tokens = tokens[:self.maxlen-1] + ['[SEP]'] #Prunning the list to be of specified max length\n",
    "        \n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens) #Obtaining the indices of the tokens in the BERT Vocabulary\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids) #Converting the list to a pytorch tensor\n",
    "\n",
    "        #Obtaining the attention mask i.e a tensor containing 1s for no padded tokens and 0s for padded ones\n",
    "        attn_mask = (tokens_ids_tensor != 0).long()\n",
    "\n",
    "        return tokens_ids_tensor, attn_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3SR2B4IhvQQz"
   },
   "outputs": [],
   "source": [
    "train_set = TweetDataset(series = train_data_concatenated, labels = y_train, maxlen = 512)\n",
    "dev_set = TweetDataset(series = dev_data_concatenated, labels = y_dev, maxlen = 512)\n",
    "test_set = TweetDataset(series = test_data_concatenated, labels = [\"NaN\" for i in test_data_concatenated], maxlen = 512)\n",
    "\n",
    "#Creating intsances of training and development dataloaders\n",
    "train_loader = DataLoader(train_set, batch_size = 8, num_workers = 2)\n",
    "dev_loader = DataLoader(dev_set, batch_size = 8, num_workers = 2)\n",
    "test_loader = DataLoader(test_set, batch_size = 8, num_workers = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
    "    print(it)\n",
    "    print(seq)\n",
    "    print(attn_masks)\n",
    "    print(labels)\n",
    "    break\n",
    "    #seq, attn_masks, labels = seq.cuda(gpu), attn_masks.cuda(gpu), labels.cuda(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "9N2wTl_DwyHo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "class RumourDetector(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(RumourDetector, self).__init__()\n",
    "        #Instantiating BERT model object \n",
    "        #self.bert_layer = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
    "        \n",
    "        self.bert_layer = BertModel.from_pretrained('bert-base-uncased')\n",
    "        #Classification layer\n",
    "        #input dimension is 768 because [CLS] embedding has a dimension of 768\n",
    "        #output dimension is 1 because we're working with a binary classification problem\n",
    "        #self.hidden_layer_1 = nn.Linear(768, 16)\n",
    "        \n",
    "        self.cls_layer = nn.Linear(768, 1)\n",
    "\n",
    "    def forward(self, seq, attn_masks):\n",
    "        '''\n",
    "        Inputs:\n",
    "            -seq : Tensor of shape [B, T] containing token ids of sequences\n",
    "            -attn_masks : Tensor of shape [B, T] containing attention masks to be used to avoid contibution of PAD tokens\n",
    "        '''\n",
    "\n",
    "        #Feeding the input to BERT model to obtain contextualized representations\n",
    "        outputs = self.bert_layer(seq, attention_mask = attn_masks, return_dict=True)\n",
    "        cont_reps = outputs.last_hidden_state\n",
    "\n",
    "        #Obtaining the representation of [CLS] head (the first token)\n",
    "        bert_rep = cont_reps[:, 0]\n",
    "        \n",
    "        #hidden_1 = self.hidden_layer_1(bert_rep)\n",
    "        #print(bert_rep.shape)\n",
    "        #Feeding cls_rep to the classifier layer\n",
    "        logits = self.cls_layer(bert_rep)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.1+cu101\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJc3WJs-w3DA",
    "outputId": "49faf802-6a5f-4090-c596-3f232b6c6153"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done creating the sentiment classifier.\n"
     ]
    }
   ],
   "source": [
    "gpu = 0 #gpu ID\n",
    "\n",
    "print(\"Creating the sentiment classifier, initialised with pretrained BERT-BASE parameters...\")\n",
    "net = RumourDetector()\n",
    "net.cuda(gpu) #Enable gpu support for the model\n",
    "print(\"Done creating the sentiment classifier.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "34VlaUR6xbLz"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "OPLrh2-Sxjvb"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def train(net, criterion, opti, train_loader, dev_loader, max_eps, gpu):\n",
    "\n",
    "    best_acc = 0\n",
    "    st = time.time()\n",
    "    for ep in range(max_eps):\n",
    "        \n",
    "        net.train()\n",
    "        print('0')\n",
    "        for it, (seq, attn_masks, labels) in enumerate(train_loader):\n",
    "            #Clear gradients\n",
    "            opti.zero_grad()  \n",
    "            #Converting these to cuda tensors\n",
    "            seq, attn_masks, labels = seq.cuda(gpu), attn_masks.cuda(gpu), labels.cuda(gpu)\n",
    "            print('1')\n",
    "            #Obtaining the logits from the model\n",
    "            logits = net(seq, attn_masks)\n",
    "            print('2')\n",
    "            #Computing loss\n",
    "            loss = criterion(logits.squeeze(-1), labels.float())\n",
    "\n",
    "            #Backpropagating the gradients\n",
    "            loss.backward()\n",
    "\n",
    "            #Optimization step\n",
    "            opti.step()\n",
    "              \n",
    "            if it % 100 == 0:\n",
    "                \n",
    "                acc = get_accuracy_from_logits(logits, labels)\n",
    "                print(\"Iteration {} of epoch {} complete. Loss: {}; Accuracy: {}; Time taken (s): {}\".format(it, ep, loss.item(), acc, (time.time()-st)))\n",
    "                st = time.time()\n",
    "\n",
    "        \n",
    "        dev_acc, dev_loss = evaluate(net, criterion, dev_loader, gpu)\n",
    "        print(\"Epoch {} complete! Development Accuracy: {}; Development Loss: {}\".format(ep, dev_acc, dev_loss))\n",
    "        if dev_acc > best_acc:\n",
    "            print(\"Best development accuracy improved from {} to {}, saving model...\".format(best_acc, dev_acc))\n",
    "            best_acc = dev_acc\n",
    "            torch.save(net.state_dict(), 'sstcls_{}.dat'.format(ep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "z02V5SLAxmZl"
   },
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "    soft_probs = (probs > 0.5).long()\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    # print(soft_probs.squeeze())\n",
    "    # print(np.array(soft_probs.squeeze().cpu()))\n",
    "    return acc\n",
    "\n",
    "def evaluate(net, criterion, dataloader, gpu):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for seq, attn_masks, labels in dataloader:\n",
    "            seq, attn_masks, labels = seq.cuda(gpu), attn_masks.cuda(gpu), labels.cuda(gpu)\n",
    "            logits = net(seq, attn_masks)\n",
    "            #print(logits)\n",
    "            mean_loss += criterion(logits.squeeze(-1), labels.float()).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "\n",
    "    return mean_acc / count, mean_loss / count\n",
    "\n",
    "def get_prediction_from_logits(logits, labels):\n",
    "    probs = torch.sigmoid(logits.unsqueeze(-1))\n",
    "    soft_probs = (probs > 0.5).long()\n",
    "    return soft_probs.squeeze()\n",
    "def predict(net, criterion, dataloader, gpu):\n",
    "    net.eval()\n",
    "\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "\n",
    "    prediction = np.array([])\n",
    "    with torch.no_grad():\n",
    "        for seq, attn_masks, labels in dataloader:\n",
    "            seq, attn_masks = seq.cuda(gpu), attn_masks.cuda(gpu)\n",
    "            logits = net(seq, attn_masks)\n",
    "            #print(logits)\n",
    "            #print(get_prediction_from_logits(logits, labels).data.cpu().numpy())\n",
    "            \n",
    "            prediction = np.concatenate((prediction, get_prediction_from_logits(logits, labels).data.cpu().numpy()), axis=0)\n",
    "            #print(prediction)\n",
    "    #predict.data.numpy()\n",
    "\n",
    "\n",
    "    return prediction.astype('int32')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tUeMABsxnWJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 1\n",
    "\n",
    "#fine-tune the model\n",
    "train(net, criterion, opti, train_loader, dev_loader, num_epoch, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cMvQSXf-7lPF",
    "outputId": "3845de8f-baa2-48a1-d955-bc42eb3dbd28"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"sstcls_4.dat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFtEmncDDfHe"
   },
   "outputs": [],
   "source": [
    "y_predict = predict(net, criterion, test_loader, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "Lqx0LDmaRJ-n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "b5_hmg2HRJMx",
    "outputId": "489212da-b5e7-400d-fe4d-10ce0d7d2f2c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-ee06fbc8-2304-410c-94ea-affdc183368f\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>557</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 2 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ee06fbc8-2304-410c-94ea-affdc183368f')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-ee06fbc8-2304-410c-94ea-affdc183368f button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-ee06fbc8-2304-410c-94ea-affdc183368f');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      Id  Predicted\n",
       "0      0          0\n",
       "1      1          1\n",
       "2      2          0\n",
       "3      3          0\n",
       "4      4          0\n",
       "..   ...        ...\n",
       "553  553          0\n",
       "554  554          0\n",
       "555  555          1\n",
       "556  556          0\n",
       "557  557          0\n",
       "\n",
       "[558 rows x 2 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "index = [i for i in range(558)]\n",
    "dataframe = pd.DataFrame({'Id':index,'Predicted':y_predict})\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "WbJnT2b6RVAW"
   },
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"nlp4.csv\",index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRessgWyGVDR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vW04Wc12GVF7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Oexz735nGVKH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BI-Ef5w4GVNM"
   },
   "outputs": [],
   "source": [
    "# playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AOJmmPR3KIcg",
    "outputId": "81472be2-5179-42bf-8b2d-2cfe51c1ff65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([])\n",
    "b = np.array([1, 2, 3])\n",
    "np.concatenate((a, b), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JEXp0GPmDzSw",
    "outputId": "f6bba124-93b2-4268-8e3f-fa5e8f704ebc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9704, device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "id": "vSgRPVU_2OSf"
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tx4PeuNQ2Tea",
    "outputId": "e5f16c89-6f52-4821-a178-5c9c83257ddb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10725"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "AqbGeD0n2aQu",
    "outputId": "0b9fd556-d168-4581-9373-d30120fc7478"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 1            |        cudaMalloc retries: 1         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   13497 MB |   13497 MB |   22203 MB |    8705 MB |\\n|       from large pool |   13492 MB |   13492 MB |   22196 MB |    8704 MB |\\n|       from small pool |       4 MB |       4 MB |       6 MB |       1 MB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   13497 MB |   13497 MB |   22203 MB |    8705 MB |\\n|       from large pool |   13492 MB |   13492 MB |   22196 MB |    8704 MB |\\n|       from small pool |       4 MB |       4 MB |       6 MB |       1 MB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   13506 MB |   13506 MB |   13506 MB |       0 B  |\\n|       from large pool |   13500 MB |   13500 MB |   13500 MB |       0 B  |\\n|       from small pool |       6 MB |       6 MB |       6 MB |       0 B  |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |    8878 KB |  632238 KB |    1900 MB |    1892 MB |\\n|       from large pool |    7464 KB |  630056 KB |    1893 MB |    1886 MB |\\n|       from small pool |    1414 KB |    2694 KB |       7 MB |       6 MB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     844    |     844    |     881    |      37    |\\n|       from large pool |     333    |     333    |     359    |      26    |\\n|       from small pool |     511    |     511    |     522    |      11    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     844    |     844    |     881    |      37    |\\n|       from large pool |     333    |     333    |     359    |      26    |\\n|       from small pool |     511    |     511    |     522    |      11    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     172    |     172    |     172    |       0    |\\n|       from large pool |     169    |     169    |     169    |       0    |\\n|       from small pool |       3    |       3    |       3    |       0    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |       7    |      10    |      61    |      54    |\\n|       from large pool |       4    |       6    |      53    |      49    |\\n|       from small pool |       3    |       6    |       8    |       5    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXtc9Fg_zvxJ",
    "outputId": "842d2990-f217-46f0-e38d-98bc674bb770"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  9 12:39:34 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   44C    P0    28W /  70W |  14922MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ArbiyK4YyBMn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "bert.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "07484f1e51144e20bade63b314b25f85": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fcfd4900c40c418aa98c722fe18e7541",
      "max": 542529064,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8fdce060e94e415f83517dbdb78dcff0",
      "value": 542529064
     }
    },
    "0bb6df41df624a748f20d3954482f5c7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d4a80b1185d4ece8389abe181932dfc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1085b6e331b44341aa3b00c3d593ff7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a915344a9a494b46924f4b2a1d4ff636",
      "placeholder": "​",
      "style": "IPY_MODEL_0d4a80b1185d4ece8389abe181932dfc",
      "value": " 824k/824k [00:01&lt;00:00, 1.14MB/s]"
     }
    },
    "18ea6393dc4c48b191c2bf093e076bd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b2aadb0f485548beb2fec780f402db0f",
      "placeholder": "​",
      "style": "IPY_MODEL_31f3d4f05f3e4f709eb18d83247350f5",
      "value": " 558/558 [00:00&lt;00:00, 18.6kB/s]"
     }
    },
    "20c0f14bf56341d4997bad737072d5d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29bfbc1c878f461fad13534524bc6bd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9554f30caa9f45de91ff9145fb89f223",
      "placeholder": "​",
      "style": "IPY_MODEL_20c0f14bf56341d4997bad737072d5d7",
      "value": "Downloading: 100%"
     }
    },
    "2cb358b2d131453f86cce27695828315": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31f3d4f05f3e4f709eb18d83247350f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "35c6a5a621ff410bbcb1f3f9d69f2491": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "39f18c40b88c48e68023c1702c4e0917": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_532ceae399644f42aaafd22b77927ffb",
       "IPY_MODEL_a47b58dd2dac468d8399105699b25a4a",
       "IPY_MODEL_1085b6e331b44341aa3b00c3d593ff7b"
      ],
      "layout": "IPY_MODEL_ba9f03fd9dec4ab79a438c56a009183f"
     }
    },
    "45b2a914e9e145d591a1a8f91b1fa0a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_608eb86bda3f4ede8ecef68e6e16cdcb",
       "IPY_MODEL_e6c8d80a49414169b03c2542430d6ab7",
       "IPY_MODEL_7e18fcb123844cbea80966d3110d6244"
      ],
      "layout": "IPY_MODEL_2cb358b2d131453f86cce27695828315"
     }
    },
    "460fd4497e444a0d837b78b48cd0902e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "500347b066ea42dfbd0eb60ffce509c8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "532ceae399644f42aaafd22b77927ffb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0bb6df41df624a748f20d3954482f5c7",
      "placeholder": "​",
      "style": "IPY_MODEL_fcc76ed5a32b4075a8301cd2bd48566e",
      "value": "Downloading: 100%"
     }
    },
    "5525864516fa4a9dbe3d339e4b72c66a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_29bfbc1c878f461fad13534524bc6bd8",
       "IPY_MODEL_8a298906448646e2b01f6e10feabdb10",
       "IPY_MODEL_18ea6393dc4c48b191c2bf093e076bd6"
      ],
      "layout": "IPY_MODEL_7757b8faf63b447bb4393f56c1c905dd"
     }
    },
    "5b30c831f0c9470eb1372c3d9d70a505": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_c69e540a903942a3abed6113f8cbb614",
       "IPY_MODEL_07484f1e51144e20bade63b314b25f85",
       "IPY_MODEL_7f3a566e218e4f2c81e1a1bd2c7e0845"
      ],
      "layout": "IPY_MODEL_8ba31786a08745d0902ed353ffca8698"
     }
    },
    "5bb0b8f8400c4d3cbe71ae18c22631d1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "608eb86bda3f4ede8ecef68e6e16cdcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be7d951aa1d7449fb0690fa9054665d8",
      "placeholder": "​",
      "style": "IPY_MODEL_db74716cb2ff404e9db46acd84f2846f",
      "value": "Downloading: 100%"
     }
    },
    "7757b8faf63b447bb4393f56c1c905dd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e18fcb123844cbea80966d3110d6244": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ee82db5c4e944fc88403d720429f84e0",
      "placeholder": "​",
      "style": "IPY_MODEL_35c6a5a621ff410bbcb1f3f9d69f2491",
      "value": " 1.03M/1.03M [00:01&lt;00:00, 1.21MB/s]"
     }
    },
    "7f3a566e218e4f2c81e1a1bd2c7e0845": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_500347b066ea42dfbd0eb60ffce509c8",
      "placeholder": "​",
      "style": "IPY_MODEL_5bb0b8f8400c4d3cbe71ae18c22631d1",
      "value": " 517M/517M [00:35&lt;00:00, 16.7MB/s]"
     }
    },
    "8a298906448646e2b01f6e10feabdb10": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aca093bd94e043c2a2cb40808c531b25",
      "max": 558,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ffe912f15e7543f396be439177375e87",
      "value": 558
     }
    },
    "8ba31786a08745d0902ed353ffca8698": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8fdce060e94e415f83517dbdb78dcff0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9554f30caa9f45de91ff9145fb89f223": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a47b58dd2dac468d8399105699b25a4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fe7ae1cd82bf41bcb789a28898b7113c",
      "max": 843438,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_dd8e246c522c48dc97e504c01fa380e7",
      "value": 843438
     }
    },
    "a915344a9a494b46924f4b2a1d4ff636": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aca093bd94e043c2a2cb40808c531b25": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b2aadb0f485548beb2fec780f402db0f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba9f03fd9dec4ab79a438c56a009183f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bb476ccfe9a042ee929f08427feee398": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be7d951aa1d7449fb0690fa9054665d8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c69e540a903942a3abed6113f8cbb614": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb476ccfe9a042ee929f08427feee398",
      "placeholder": "​",
      "style": "IPY_MODEL_460fd4497e444a0d837b78b48cd0902e",
      "value": "Downloading: 100%"
     }
    },
    "db74716cb2ff404e9db46acd84f2846f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dd8e246c522c48dc97e504c01fa380e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e6c8d80a49414169b03c2542430d6ab7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eb53b1ffe64b41b6b6441a3dbee00f45",
      "max": 1078931,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_eca6fd45776549c0a8c7065dd2feee6c",
      "value": 1078931
     }
    },
    "eb53b1ffe64b41b6b6441a3dbee00f45": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eca6fd45776549c0a8c7065dd2feee6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ee82db5c4e944fc88403d720429f84e0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fcc76ed5a32b4075a8301cd2bd48566e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fcfd4900c40c418aa98c722fe18e7541": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fe7ae1cd82bf41bcb789a28898b7113c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffe912f15e7543f396be439177375e87": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
